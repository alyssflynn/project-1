{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "--------------------\n",
    "Question 1: Is there a relationship between exposure to poor air quality and incidences of cancer?\n",
    "\n",
    "Question 2: Does your probability of developing a certain type of cancer change depending on your geographic location in the US?\n",
    "\n",
    "Question 3: How well can you predict (cancer instances/risk/rate) from AQI and year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from config import state_abbrev, reverse_state_abbrev, state_codes, us_state_abbrev\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "import statsmodels as sm\n",
    "import sklearn as sk\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scatterplot(df, group_by=[], x='', y='', xlabel='', ylabel='', main_title='', legend_title='', linestyle='', return_obj=False):\n",
    "    '''Function to make a scatterplot out of desired data'''\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.margins(0.05)\n",
    "    \n",
    "    groups = df.groupby(group_by)\n",
    "    \n",
    "    # Scatterplot with cancer sites as categories \n",
    "    for name, group in groups:\n",
    "        if len(group_by) > 1: \n",
    "            lbl=name #[-1]\n",
    "        else: lbl=name\n",
    "#         print(name)\n",
    "        ax.plot(group[x], group[y], animated=True,\n",
    "                marker='o', ms=3, linestyle=linestyle, label=lbl)\n",
    "    \n",
    "    if xlabel == '': xlabel = x\n",
    "    if ylabel == '': ylabel = y\n",
    "    if main_title == '': main_title = '{y} vs {x}'.format(y=y, x=x)\n",
    "    \n",
    "    # Set plot attributes\n",
    "    plt.xlim(min(df[x]), max(df[x]))\n",
    "    plt.ylim(min(df[y]), max(df[y]))\n",
    "    fig.suptitle(main_title)\n",
    "    ax.legend(bbox_to_anchor=(1.55, 1), title=legend_title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    if return_obj == True:\n",
    "        return plt\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_county_choropleth(df, values='', fips='', title='', data=''):\n",
    "    value_key = values\n",
    "    values = df['{}'.format(values)].tolist()\n",
    "    fips = df['{}'.format(fips)].tolist()\n",
    "    \n",
    "    if data == 'aqi':\n",
    "        colors = {\"good\": \"#1fca23\", \"moderate\": \"#fffd38\", \"usg\":\"#fc6621\",  \n",
    "                        \"unhealthy\": \"#fc0d1b\", \"very unhealthy\":\"#97084c\", \n",
    "                        \"hazardous\":\"#7d0425\", \"off scale\":\"#000000\"}\n",
    "        colorscale=colors.values()\n",
    "        endpts = [50, 100, 150, 200, 300, 500]\n",
    "        \n",
    "    elif data == 'population':\n",
    "        colorscale = ['rgb(193, 193, 193)',\n",
    "                      'rgb(239,239,239)',\n",
    "                      'rgb(195, 196, 222)',\n",
    "                      'rgb(144,148,194)',\n",
    "                      'rgb(101,104,168)',\n",
    "                      'rgb(65, 53, 132)']\n",
    "        endpts=[14348, 63983, 134827, 426762, 2081313]\n",
    "        \n",
    "    elif data == 'cancer':\n",
    "        colorscale = [\"#ebf3fb\",\"#deebf7\",\"#d2e3f3\",\"#c6dbef\",\n",
    "                      \"#b3d2e9\",\"#9ecae1\",\"#85bcdb\",\"#6baed6\",\"#57a0ce\"]\n",
    "        endpts = list(np.mgrid[0:max(values):5j])\n",
    "        \n",
    "    else:\n",
    "        colorscale = colorscale = [\"#ff0000\",\"#ff9900\",\"#ffff00\",\n",
    "                                   \"#ccff33\",\"#33cc33\", \"#bfbfbf\"]\n",
    "        endpts = endpts = list(np.mgrid[0:max(values):5j])\n",
    "        \n",
    "    fig = ff.create_choropleth(\n",
    "        fips = fips, values = values,\n",
    "        scope=['usa'],\n",
    "        binning_endpoints = endpts,\n",
    "        colorscale= colorscale,\n",
    "        show_state_data=True,\n",
    "        county_outline={'color': 'rgb(0,0,0)', 'width': 0.5},\n",
    "        show_hover=True, centroid_marker={'opacity': 0},\n",
    "        asp=2.9,\n",
    "        title=title,\n",
    "        legend_title=value_key)\n",
    "    py.iplot(fig, filename='choropleth_full_usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQI Data Headers:\n",
      " ['State', 'County', 'State Abbreviation', 'Year', 'FIPS', 'State FIPS Code', 'County FIPS Code', 'Max AQI', '90th Percentile AQI', '% Days AQI Unhealthy-Hazardous', '% Days CO', '% Days NO2', '% Days SO2', '% Days Ozone', '% Days PM2.5', '% Days PM10']\n",
      "\n",
      "Cancer Data Headers:\n",
      " ['State', 'State Abbreviation', 'Year', 'Cancer Sites', 'Count']\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "aqi = pd.read_csv(\"clean_data/aqi_1980_2018.csv\", index_col=0)        # AQI data by state/county: 1980-2018\n",
    "cancer = pd.read_csv(\"clean_data/cancer_1998_2014.csv\", index_col=0)  # Cancer data by state: 1998-2014\n",
    "print(\"AQI Data Headers:\\n\", aqi.keys().tolist())\n",
    "print(\"\\nCancer Data Headers:\\n\", cancer.keys().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>State Abbreviation</th>\n",
       "      <th>Year</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State FIPS Code</th>\n",
       "      <th>County FIPS Code</th>\n",
       "      <th>Max AQI</th>\n",
       "      <th>90th Percentile AQI</th>\n",
       "      <th>% Days AQI Unhealthy-Hazardous</th>\n",
       "      <th>% Days CO</th>\n",
       "      <th>% Days NO2</th>\n",
       "      <th>% Days SO2</th>\n",
       "      <th>% Days Ozone</th>\n",
       "      <th>% Days PM2.5</th>\n",
       "      <th>% Days PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>1980</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>108</td>\n",
       "      <td>2.234637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.843575</td>\n",
       "      <td>68.156425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama</td>\n",
       "      <td>autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>1981</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "      <td>77</td>\n",
       "      <td>1.120448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.492997</td>\n",
       "      <td>67.507003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama</td>\n",
       "      <td>autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>1982</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>206</td>\n",
       "      <td>67</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.244898</td>\n",
       "      <td>67.755102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alabama</td>\n",
       "      <td>autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>1989</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alabama</td>\n",
       "      <td>autauga</td>\n",
       "      <td>AL</td>\n",
       "      <td>1990</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>93</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State   County State Abbreviation  Year  FIPS  State FIPS Code  \\\n",
       "0  alabama  autauga                 AL  1980  1001                1   \n",
       "1  alabama  autauga                 AL  1981  1001                1   \n",
       "2  alabama  autauga                 AL  1982  1001                1   \n",
       "3  alabama  autauga                 AL  1989  1001                1   \n",
       "4  alabama  autauga                 AL  1990  1001                1   \n",
       "\n",
       "   County FIPS Code  Max AQI  90th Percentile AQI  \\\n",
       "0                 1      177                  108   \n",
       "1                 1      195                   77   \n",
       "2                 1      206                   67   \n",
       "3                 1      100                   64   \n",
       "4                 1      151                   93   \n",
       "\n",
       "   % Days AQI Unhealthy-Hazardous  % Days CO  % Days NO2  % Days SO2  \\\n",
       "0                        2.234637        0.0         0.0   31.843575   \n",
       "1                        1.120448        0.0         0.0   32.492997   \n",
       "2                        0.408163        0.0         0.0   32.244898   \n",
       "3                        0.000000        0.0         0.0    0.000000   \n",
       "4                        0.375940        0.0         0.0    0.000000   \n",
       "\n",
       "   % Days Ozone  % Days PM2.5  % Days PM10  \n",
       "0     68.156425           0.0          0.0  \n",
       "1     67.507003           0.0          0.0  \n",
       "2     67.755102           0.0          0.0  \n",
       "3    100.000000           0.0          0.0  \n",
       "4    100.000000           0.0          0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How has air quality changed since 1980?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The map displays a functioning slider and index, however the values/color gradient for the individual states is not displaying.  \n",
    "\n",
    "# url = 'https://raw.githubusercontent.com/alyssflynn/project-1/master/clean_data/county_aqi_1980_2018.csv'\n",
    "# dataset = pd.read_csv(url)\n",
    "# years = sorted(list(set(dataset.Year)))\n",
    "\n",
    "# data = []\n",
    "\n",
    "# for year in years:\n",
    "#     df = dataset[dataset.Year ==year].copy(deep=True)\n",
    "#     this_dict = dict(type='choropleth',\n",
    "#              locations = df['State Abbreviation'].astype(str),\n",
    "#              z=df['Median AQI'].astype(float), # for whatever reason the values of \"Max AQI\" are not displaying in the map.\n",
    "#              locationmode=\"USA-states\")\n",
    "#     data.append(this_dict)\n",
    "# # let's create the steps for the slider\n",
    "# steps = []\n",
    "# for i in range(len(data)):\n",
    "#     step = dict(method='restyle',\n",
    "#                 args=['visible', [False] * len(data)],\n",
    "#                 label='Year {}'.format(i + 1980))\n",
    "#     step['args'][1][i] = True\n",
    "#     steps.append(step)\n",
    "\n",
    "# sliders = [dict(active=0,\n",
    "#                 pad={\"t\": 1},\n",
    "#                 steps=steps)]    \n",
    "# layout = dict(geo=dict(scope='usa',\n",
    "#                        projection={'type': 'Mercator'}),\n",
    "#               sliders=sliders)\n",
    "\n",
    "# fig = dict(data=data, \n",
    "#            layout=layout)\n",
    "# py.iplot(fig, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'raw_data/pollution_us_2000_2016.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8c124f24044b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpollution_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_data/pollution_us_2000_2016.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m pollution_data.drop(['Unnamed: 0','Site Num','Address',\n\u001b[1;32m      3\u001b[0m                     'NO2 Units','O3 Units','SO2 Units','CO Units'],axis=1)\n\u001b[1;32m      4\u001b[0m pollution_data_c = pollution_data[['State','County','State Code','County Code','City',\n\u001b[1;32m      5\u001b[0m                                   'Date Local','NO2 AQI','O3 AQI','SO2 AQI','CO AQI']]\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'raw_data/pollution_us_2000_2016.csv' does not exist"
     ]
    }
   ],
   "source": [
    "pollution_data = pd.read_csv(\"raw_data/pollution_us_2000_2016.csv\")\n",
    "pollution_data.drop(['Unnamed: 0','Site Num','Address',\n",
    "                    'NO2 Units','O3 Units','SO2 Units','CO Units'],axis=1)\n",
    "pollution_data_c = pollution_data[['State','County','State Code','County Code','City',\n",
    "                                  'Date Local','NO2 AQI','O3 AQI','SO2 AQI','CO AQI']]\n",
    "pollution_data_c = pollution_data_c.dropna(axis='rows')\n",
    "pollution_data_c = pollution_data_c[pollution_data_c.State!='Country Of Mexico']\n",
    "pollution_data_c['Date Local'] = pd.to_datetime(pollution_data_c['Date Local'],format='%Y-%m-%d')\n",
    "pollution_data_c['Date Local'] = pollution_data_c['Date Local'].apply(str)\n",
    "pollution_data_c['State Code'] = pollution_data_c['State Code'].apply(str)\n",
    "pollution_data_c['County Code'] = pollution_data_c['County Code'].apply(str)\n",
    "pollution_data_c['Year'] = pollution_data_c['Date Local'].apply(lambda x: x.split(\"-\")[0])\n",
    "pollution_data_c['Month'] = pollution_data_c['Date Local'].apply(lambda x: x.split(\"-\")[1])\n",
    "pollution_data_c['Day'] = pollution_data_c['Date Local'].apply(lambda x: x.split(\"-\")[2])\n",
    "pollution_data_c = pollution_data_c.rename(columns = {\"State Code\": \"State Code (FIPS)\"})\n",
    "pollution_data_c['State Code (FIPS)'] = pollution_data_c['State Code (FIPS)'].apply(lambda x: str(x).zfill(2))\n",
    "pollution_data_c['County Code'] = pollution_data_c['County Code'].apply(lambda x: str(x).zfill(3))\n",
    "pollution_data_c['FIPS'] = pollution_data_c['State Code (FIPS)'] + pollution_data_c['County Code']\n",
    "pollution_data_c['Year'] = pollution_data_c['Year'].apply(int)\n",
    "\n",
    "pollution_data_c = pollution_data_c.groupby(['Year','State'], as_index=False).mean()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "pollution_data_c = pollution_data_c.groupby(['Year'])[['Year', 'NO2 AQI', 'O3 AQI', 'SO2 AQI', 'CO AQI']].mean()\n",
    "pollution_data_c.plot(kind='line', x='Year', y=['NO2 AQI', 'O3 AQI', 'SO2 AQI', 'CO AQI'], figsize=(30, 15))\n",
    "plt.title(\"United States: Air Pollution AQI from 2000-2016\")\n",
    "plt.ylabel(\"AQI Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll = pd.read_csv(\"raw_data/pollution_us_2000_2016.csv\")\n",
    "\n",
    "poll = poll.drop(['Unnamed: 0','State Code','County Code','Site Num','Address','NO2 Units','O3 Units','SO2 Units','CO Units'],axis=1)\n",
    "\n",
    "\n",
    "## Prepare all 4 AQIs against state and date \n",
    "pollSt = poll[['State','Date Local','NO2 AQI','O3 AQI','SO2 AQI','CO AQI']]\n",
    "pollSt = pollSt.dropna(axis='rows')  # Delete rows with NAs\n",
    "pollSt = pollSt[pollSt.State!='Country Of Mexico']  # Delete Mexico\n",
    "pollSt['Date Local'] = pd.to_datetime(pollSt['Date Local'],format='%Y-%m-%d')  # Change date from string to date value\n",
    "pollSt = pollSt.groupby(['State','Date Local']).mean()  # Take mean values if there are depulicated entries\n",
    "pollStGrouped = pollSt.groupby(level=0)\n",
    "\n",
    "## Plot 4 AQIs with top 4 states\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# NO2 AQI\n",
    "plt.subplot(221)\n",
    "pollNO2 = pollStGrouped['NO2 AQI']\n",
    "pollNO2Top = pollNO2.mean().nlargest(4).index\n",
    "for i in range(len(pollNO2Top)):\n",
    "    pollNO2.get_group(pollNO2Top[i]).groupby(pd.Grouper(level='Date Local',freq='M')).mean().plot()\n",
    "plt.legend(pollNO2Top,loc=3,fontsize='small')\n",
    "plt.title('NO2 AQI')\n",
    "\n",
    "# O3 AQI\n",
    "plt.subplot(222)\n",
    "pollO3 = pollStGrouped['O3 AQI']\n",
    "pollO3Top = pollO3.mean().nlargest(4).index\n",
    "for i in range(len(pollO3Top)):\n",
    "    pollO3.get_group(pollO3Top[i]).groupby(pd.Grouper(level='Date Local',freq='M')).mean().plot()\n",
    "plt.legend(pollO3Top,loc=3,fontsize='small')\n",
    "plt.title('O3 AQI')\n",
    "\n",
    "# SO2 AQI\n",
    "plt.subplot(223)\n",
    "pollSO2 = pollStGrouped['SO2 AQI']\n",
    "pollSO2Top = pollSO2.mean().nlargest(4).index\n",
    "for i in range(len(pollSO2Top)):\n",
    "    pollSO2.get_group(pollSO2Top[i]).groupby(pd.Grouper(level='Date Local',freq='M')).mean().plot()\n",
    "plt.legend(pollSO2Top,loc=3,fontsize='small')\n",
    "plt.title('SO2 AQI')\n",
    "\n",
    "# CO AQI\n",
    "plt.subplot(224)\n",
    "pollCO = pollStGrouped['CO AQI']\n",
    "pollCOTop = pollCO.mean().nlargest(4).index\n",
    "for i in range(len(pollCOTop)):\n",
    "    pollCO.get_group(pollCOTop[i]).groupby(pd.Grouper(level='Date Local',freq='M')).mean().plot()\n",
    "plt.legend(pollCOTop,loc=3,fontsize='small')\n",
    "plt.title('CO AQI')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll = pd.read_csv(\"raw_data/pollution_us_2000_2016.csv\")\n",
    "\n",
    "poll = poll.drop(['Unnamed: 0','State Code','County Code','Site Num','Address','NO2 Units','O3 Units','SO2 Units','CO Units'],axis=1)\n",
    "poll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollStO3 = pollStO3.reset_index()\n",
    "pollStO3 = pollStO3[pollStO3['State']!='District Of Columbia']\n",
    "pollStO3['State_abbrev'] = pollStO3.State.apply(lambda x: us_state_abbrev[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create 'dynamic' colorscale - it seems plotly doesn't provide fixed colorscale, so we should keep the colorcode fixed with some calculation...\n",
    "def scale(aqiSeries):\n",
    "    cmax = aqiSeries.max()\n",
    "    cmin = aqiSeries.min()\n",
    "    dt = 1e-5\n",
    "    cg = min((50-cmin)/(cmax-cmin)+dt,1.0)\n",
    "    cy = min((100-cmin)/(cmax-cmin)+dt,1.0)\n",
    "    co = min((150-cmin)/(cmax-cmin)+dt,1.0)\n",
    "    cr = min((200-cmin)/(cmax-cmin)+dt,1.0)\n",
    "    cp = min((300-cmin)/(cmax-cmin)+dt,1.0)\n",
    "    cm = min((500-cmin)/(cmax-cmin)+dt,1.0)\n",
    "\n",
    "    colorcode = [cg,cy,co,cr,cp,cm]\n",
    "    colors = ['green','yellow','orange','red','purple','maroon']\n",
    "    scl = []\n",
    "    prev = 0\n",
    "    for i in range(len(colorcode)):\n",
    "        scl.extend([[prev,colors[i]],[colorcode[i],colors[i]]])\n",
    "        prev=colorcode[i]\n",
    "        if colorcode[i]==1.0: break\n",
    "    \n",
    "    return scl\n",
    "## Create MaxAQI and MAXAQIValue that dipict the worst AQI and its value of the month\n",
    "pMonth = []\n",
    "months = ['2015-01-31','2015-02-28','2015-03-31','2015-04-30','2015-05-31','2015-06-30',\n",
    "        '2015-07-31','2015-08-31','2015-09-30','2015-10-31','2015-11-30','2015-12-31']\n",
    "\n",
    "pollStMonth = pollSt.reset_index(level=0).groupby(['State']).resample('M').max().drop(['State'],axis=1)\n",
    "pollStMonth = pollStMonth.reset_index()\n",
    "\n",
    "for i,month in enumerate(months):\n",
    "    p = pollStMonth[pollStMonth['Date Local']==month].copy()\n",
    "    p['MaxAQIValue'] = p.max(axis=1)\n",
    "    p['MaxAQI'] = p.drop(['State','Date Local'],axis=1).idxmax(axis=1)\n",
    "\n",
    "    p = p[p['State']!='District Of Columbia']\n",
    "    p['State_abbrev'] = p.State.apply(lambda x: us_state_abbrev[x])\n",
    "    pMonth.append(p[p['MaxAQI'].notnull()])\n",
    "\n",
    "data=[]\n",
    "layout = dict(\n",
    "        title = 'Monthly Max AQI in 2015',\n",
    "        width = 1000,\n",
    "        height = 600\n",
    ")\n",
    "\n",
    "for i in range(12):\n",
    "    geo_key = 'geo'+str(i+1) if i != 0 else 'geo'\n",
    "    data.append(dict(\n",
    "        type='choropleth',\n",
    "        locationmode = 'USA-states',\n",
    "        z = pMonth[i]['MaxAQIValue'],\n",
    "        colorscale = scale(pMonth[i]['MaxAQIValue']),\n",
    "        autocolorscale = False,\n",
    "        locations = pMonth[i].State_abbrev,\n",
    "        text = pMonth[i]['MaxAQI'].apply(lambda x:x[:-3]),\n",
    "        showscale =False,\n",
    "        geo=geo_key,\n",
    "        marker = dict(line = dict(color='rgb(227,227,227)',width = 1.5)),\n",
    "        ))\n",
    "    \n",
    "    data.append(dict(\n",
    "        type = 'scattergeo',\n",
    "        showlegend = False,\n",
    "        lon = [-80],\n",
    "        lat = [48],\n",
    "        geo = geo_key,\n",
    "        text = months[i][:-3],\n",
    "        mode = 'text',\n",
    "        ))\n",
    "    layout[geo_key] = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            domain = dict( x = [], y = [] ),\n",
    "            lakecolor = 'rgb(255, 255, 255)')\n",
    "z = 0\n",
    "COLS = 4\n",
    "ROWS = 3\n",
    "for y in reversed(range(ROWS)):\n",
    "    for x in range(COLS):\n",
    "        geo_key = 'geo'+str(z+1) if z != 0 else 'geo'\n",
    "        layout[geo_key]['domain']['x'] = [float(x)/float(COLS), float(x+1)/float(COLS)]\n",
    "        layout[geo_key]['domain']['y'] = [float(y)/float(ROWS), float(y+1)/float(ROWS)]\n",
    "        z=z+1\n",
    "\n",
    "figure = dict(data = data, layout = layout)\n",
    "iplot(figure)\n",
    "\n",
    "########################## 2015 ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## 2014 ##########################\n",
    "## Create MaxAQI and MAXAQIValue that dipict the worst AQI and its value of the month\n",
    "pMonth = []\n",
    "\n",
    "months = ['2014-01-31','2014-02-28','2014-03-31','2014-04-30',\n",
    "            '2014-05-31','2014-06-30','2014-07-31','2014-08-31',\n",
    "            '2014-09-30','2014-10-31','2014-11-30','2014-12-31']\n",
    "\n",
    "\n",
    "pollStMonth = pollSt.reset_index(level=0).groupby(['State']).resample('M').max().drop(['State'],axis=1)\n",
    "pollStMonth = pollStMonth.reset_index()\n",
    "\n",
    "for i,month in enumerate(months):\n",
    "    p = pollStMonth[pollStMonth['Date Local']==month].copy()\n",
    "    p['MaxAQIValue'] = p.max(axis=1)\n",
    "    p['MaxAQI'] = p.drop(['State','Date Local'],axis=1).idxmax(axis=1)\n",
    "\n",
    "    p = p[p['State']!='District Of Columbia']\n",
    "    p['State_abbrev'] = p.State.apply(lambda x: us_state_abbrev[x])\n",
    "    pMonth.append(p[p['MaxAQI'].notnull()])\n",
    "\n",
    "data=[]\n",
    "layout = dict(\n",
    "        title = 'Monthly Max AQI in 2014',\n",
    "        width = 1000,\n",
    "        height = 600\n",
    ")\n",
    "\n",
    "for i in range(12):\n",
    "    geo_key = 'geo'+str(i+1) if i != 0 else 'geo'\n",
    "    data.append(dict(\n",
    "        type='choropleth',\n",
    "        locationmode = 'USA-states',\n",
    "        z = pMonth[i]['MaxAQIValue'],\n",
    "        colorscale = scale(pMonth[i]['MaxAQIValue']),\n",
    "        autocolorscale = False,\n",
    "        locations = pMonth[i].State_abbrev,\n",
    "        text = pMonth[i]['MaxAQI'].apply(lambda x:x[:-3]),\n",
    "        showscale =False,\n",
    "        geo=geo_key,\n",
    "        marker = dict(line = dict(color='rgb(227,227,227)',width = 1.5)),\n",
    "        ))\n",
    "    \n",
    "    data.append(dict(\n",
    "        type = 'scattergeo',\n",
    "        showlegend = False,\n",
    "        lon = [-80],\n",
    "        lat = [48],\n",
    "        geo = geo_key,\n",
    "        text = months[i][:-3],\n",
    "        mode = 'text',\n",
    "        ))\n",
    "    layout[geo_key] = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            domain = dict( x = [], y = [] ),\n",
    "            lakecolor = 'rgb(255, 255, 255)')\n",
    "z = 0\n",
    "COLS = 4\n",
    "ROWS = 3\n",
    "for y in reversed(range(ROWS)):\n",
    "    for x in range(COLS):\n",
    "        geo_key = 'geo'+str(z+1) if z != 0 else 'geo'\n",
    "        layout[geo_key]['domain']['x'] = [float(x)/float(COLS), float(x+1)/float(COLS)]\n",
    "        layout[geo_key]['domain']['y'] = [float(y)/float(ROWS), float(y+1)/float(ROWS)]\n",
    "        z=z+1\n",
    "\n",
    "figure = dict(data = data, layout = layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## 2013 ##########################\n",
    "## Create MaxAQI and MAXAQIValue that dipict the worst AQI and its value of the month\n",
    "pMonth = []\n",
    "# months = ['2015-01-31','2015-02-28','2015-03-31','2015-04-30','2015-05-31','2015-06-30',\n",
    "#         '2015-07-31','2015-08-31','2015-09-30','2015-10-31','2015-11-30','2015-12-31']\n",
    "\n",
    "\n",
    "months = ['2013-01-31','2013-02-28','2013-03-31','2013-04-30',\n",
    "            '2013-05-31','2013-06-30','2013-07-31','2013-08-31',\n",
    "            '2013-09-30','2013-10-31','2013-11-30','2013-12-31']\n",
    "\n",
    "\n",
    "pollStMonth = pollSt.reset_index(level=0).groupby(['State']).resample('M').max().drop(['State'],axis=1)\n",
    "pollStMonth = pollStMonth.reset_index()\n",
    "\n",
    "for i,month in enumerate(months):\n",
    "    p = pollStMonth[pollStMonth['Date Local']==month].copy()\n",
    "    p['MaxAQIValue'] = p.max(axis=1)\n",
    "    p['MaxAQI'] = p.drop(['State','Date Local'],axis=1).idxmax(axis=1)\n",
    "\n",
    "    p = p[p['State']!='District Of Columbia']\n",
    "    p['State_abbrev'] = p.State.apply(lambda x: us_state_abbrev[x])\n",
    "    pMonth.append(p[p['MaxAQI'].notnull()])\n",
    "    \n",
    "data=[]\n",
    "layout = dict(\n",
    "        title = 'Monthly Max AQI in 2013',\n",
    "        width = 1000,\n",
    "        height = 600\n",
    ")\n",
    "\n",
    "for i in range(12):\n",
    "    geo_key = 'geo'+str(i+1) if i != 0 else 'geo'\n",
    "    data.append(dict(\n",
    "        type='choropleth',\n",
    "        locationmode = 'USA-states',\n",
    "        z = pMonth[i]['MaxAQIValue'],\n",
    "        colorscale = scale(pMonth[i]['MaxAQIValue']),\n",
    "        autocolorscale = False,\n",
    "        locations = pMonth[i].State_abbrev,\n",
    "        text = pMonth[i]['MaxAQI'].apply(lambda x:x[:-3]),\n",
    "        showscale =False,\n",
    "        geo=geo_key,\n",
    "        marker = dict(line = dict(color='rgb(227,227,227)',width = 1.5)),\n",
    "        ))\n",
    "    \n",
    "    data.append(dict(\n",
    "        type = 'scattergeo',\n",
    "        showlegend = False,\n",
    "        lon = [-80],\n",
    "        lat = [48],\n",
    "        geo = geo_key,\n",
    "        text = months[i][:-3],\n",
    "        mode = 'text',\n",
    "        ))\n",
    "    layout[geo_key] = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            domain = dict( x = [], y = [] ),\n",
    "            lakecolor = 'rgb(255, 255, 255)')\n",
    "z = 0\n",
    "COLS = 4\n",
    "ROWS = 3\n",
    "for y in reversed(range(ROWS)):\n",
    "    for x in range(COLS):\n",
    "        geo_key = 'geo'+str(z+1) if z != 0 else 'geo'\n",
    "        layout[geo_key]['domain']['x'] = [float(x)/float(COLS), float(x+1)/float(COLS)]\n",
    "        layout[geo_key]['domain']['y'] = [float(y)/float(ROWS), float(y+1)/float(ROWS)]\n",
    "        z=z+1\n",
    "\n",
    "figure = dict(data = data, layout = layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## 2012 ##########################\n",
    "## Create MaxAQI and MAXAQIValue that dipict the worst AQI and its value of the month\n",
    "pMonth = []\n",
    "months = ['2012-01-31','2012-02-28','2012-03-31','2012-04-30',\n",
    "            '2012-05-31','2012-06-30','2012-07-31','2012-08-31',\n",
    "            '2012-09-30','2012-10-31','2012-11-30','2012-12-31']\n",
    "\n",
    "\n",
    "pollStMonth = pollSt.reset_index(level=0).groupby(['State']).resample('M').max().drop(['State'],axis=1)\n",
    "pollStMonth = pollStMonth.reset_index()\n",
    "\n",
    "for i,month in enumerate(months):\n",
    "    p = pollStMonth[pollStMonth['Date Local']==month].copy()\n",
    "    p['MaxAQIValue'] = p.max(axis=1)\n",
    "    p['MaxAQI'] = p.drop(['State','Date Local'],axis=1).idxmax(axis=1)\n",
    "\n",
    "    p = p[p['State']!='District Of Columbia']\n",
    "    p['State_abbrev'] = p.State.apply(lambda x: us_state_abbrev[x])\n",
    "    pMonth.append(p[p['MaxAQI'].notnull()])\n",
    "    \n",
    "data=[]\n",
    "layout = dict(\n",
    "        title = 'Monthly Max AQI in 2012',\n",
    "        width = 1000,\n",
    "        height = 600\n",
    ")\n",
    "\n",
    "for i in range(12):\n",
    "    geo_key = 'geo'+str(i+1) if i != 0 else 'geo'\n",
    "    data.append(dict(\n",
    "        type='choropleth',\n",
    "        locationmode = 'USA-states',\n",
    "        z = pMonth[i]['MaxAQIValue'],\n",
    "        colorscale = scale(pMonth[i]['MaxAQIValue']),\n",
    "        autocolorscale = False,\n",
    "        locations = pMonth[i].State_abbrev,\n",
    "        text = pMonth[i]['MaxAQI'].apply(lambda x:x[:-3]),\n",
    "        showscale =False,\n",
    "        geo=geo_key,\n",
    "        marker = dict(line = dict(color='rgb(227,227,227)',width = 1.5)),\n",
    "        ))\n",
    "    \n",
    "    data.append(dict(\n",
    "        type = 'scattergeo',\n",
    "        showlegend = False,\n",
    "        lon = [-80],\n",
    "        lat = [48],\n",
    "        geo = geo_key,\n",
    "        text = months[i][:-3],\n",
    "        mode = 'text',\n",
    "        ))\n",
    "    layout[geo_key] = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            domain = dict( x = [], y = [] ),\n",
    "            lakecolor = 'rgb(255, 255, 255)')\n",
    "z = 0\n",
    "COLS = 4\n",
    "ROWS = 3\n",
    "for y in reversed(range(ROWS)):\n",
    "    for x in range(COLS):\n",
    "        geo_key = 'geo'+str(z+1) if z != 0 else 'geo'\n",
    "        layout[geo_key]['domain']['x'] = [float(x)/float(COLS), float(x+1)/float(COLS)]\n",
    "        layout[geo_key]['domain']['y'] = [float(y)/float(ROWS), float(y+1)/float(ROWS)]\n",
    "        z=z+1\n",
    "\n",
    "figure = dict(data = data, layout = layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## 2011 ##########################\n",
    "## Create MaxAQI and MAXAQIValue that dipict the worst AQI and its value of the month\n",
    "pMonth = []\n",
    "months = ['2011-01-31','2011-02-28','2011-03-31','2011-04-30',\n",
    "            '2011-05-31','2011-06-30','2011-07-31','2011-08-31',\n",
    "            '2011-09-30','2011-10-31','2011-11-30','2011-12-31']\n",
    "\n",
    "\n",
    "pollStMonth = pollSt.reset_index(level=0).groupby(['State']).resample('M').max().drop(['State'],axis=1)\n",
    "pollStMonth = pollStMonth.reset_index()\n",
    "\n",
    "for i,month in enumerate(months):\n",
    "    p = pollStMonth[pollStMonth['Date Local']==month].copy()\n",
    "    p['MaxAQIValue'] = p.max(axis=1)\n",
    "    p['MaxAQI'] = p.drop(['State','Date Local'],axis=1).idxmax(axis=1)\n",
    "\n",
    "    p = p[p['State']!='District Of Columbia']\n",
    "    p['State_abbrev'] = p.State.apply(lambda x: us_state_abbrev[x])\n",
    "    pMonth.append(p[p['MaxAQI'].notnull()])\n",
    "    \n",
    "data=[]\n",
    "layout = dict(\n",
    "        title = 'Monthly Max AQI in 2011',\n",
    "        width = 1000,\n",
    "        height = 600\n",
    ")\n",
    "\n",
    "for i in range(12):\n",
    "    geo_key = 'geo'+str(i+1) if i != 0 else 'geo'\n",
    "    data.append(dict(\n",
    "        type='choropleth',\n",
    "        locationmode = 'USA-states',\n",
    "        z = pMonth[i]['MaxAQIValue'],\n",
    "        colorscale = scale(pMonth[i]['MaxAQIValue']),\n",
    "        autocolorscale = False,\n",
    "        locations = pMonth[i].State_abbrev,\n",
    "        text = pMonth[i]['MaxAQI'].apply(lambda x:x[:-3]),\n",
    "        showscale =False,\n",
    "        geo=geo_key,\n",
    "        marker = dict(line = dict(color='rgb(227,227,227)',width = 1.5)),\n",
    "        ))\n",
    "    \n",
    "    data.append(dict(\n",
    "        type = 'scattergeo',\n",
    "        showlegend = False,\n",
    "        lon = [-80],\n",
    "        lat = [48],\n",
    "        geo = geo_key,\n",
    "        text = months[i][:-3],\n",
    "        mode = 'text',\n",
    "        ))\n",
    "    layout[geo_key] = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            domain = dict( x = [], y = [] ),\n",
    "            lakecolor = 'rgb(255, 255, 255)')\n",
    "z = 0\n",
    "COLS = 4\n",
    "ROWS = 3\n",
    "for y in reversed(range(ROWS)):\n",
    "    for x in range(COLS):\n",
    "        geo_key = 'geo'+str(z+1) if z != 0 else 'geo'\n",
    "        layout[geo_key]['domain']['x'] = [float(x)/float(COLS), float(x+1)/float(COLS)]\n",
    "        layout[geo_key]['domain']['y'] = [float(y)/float(ROWS), float(y+1)/float(ROWS)]\n",
    "        z=z+1\n",
    "\n",
    "figure = dict(data = data, layout = layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## 2010 ##########################\n",
    "## Create MaxAQI and MAXAQIValue that dipict the worst AQI and its value of the month\n",
    "pMonth = []\n",
    "months = ['2010-01-31','2010-02-28','2010-03-31','2010-04-30',\n",
    "            '2010-05-31','2010-06-30','2010-07-31','2010-08-31',\n",
    "            '2010-09-30','2010-10-31','2010-11-30','2010-12-31']\n",
    "\n",
    "\n",
    "pollStMonth = pollSt.reset_index(level=0).groupby(['State']).resample('M').max().drop(['State'],axis=1)\n",
    "pollStMonth = pollStMonth.reset_index()\n",
    "\n",
    "for i,month in enumerate(months):\n",
    "    p = pollStMonth[pollStMonth['Date Local']==month].copy()\n",
    "    p['MaxAQIValue'] = p.max(axis=1)\n",
    "    p['MaxAQI'] = p.drop(['State','Date Local'],axis=1).idxmax(axis=1)\n",
    "\n",
    "    p = p[p['State']!='District Of Columbia']\n",
    "    p['State_abbrev'] = p.State.apply(lambda x: us_state_abbrev[x])\n",
    "    pMonth.append(p[p['MaxAQI'].notnull()])\n",
    "    \n",
    "data=[]\n",
    "layout = dict(\n",
    "        title = 'Monthly Max AQI in 2010',\n",
    "        width = 1000,\n",
    "        height = 600\n",
    ")\n",
    "\n",
    "for i in range(12):\n",
    "    geo_key = 'geo'+str(i+1) if i != 0 else 'geo'\n",
    "    data.append(dict(\n",
    "        type='choropleth',\n",
    "        locationmode = 'USA-states',\n",
    "        z = pMonth[i]['MaxAQIValue'],\n",
    "        colorscale = scale(pMonth[i]['MaxAQIValue']),\n",
    "        autocolorscale = False,\n",
    "        locations = pMonth[i].State_abbrev,\n",
    "        text = pMonth[i]['MaxAQI'].apply(lambda x:x[:-3]),\n",
    "        showscale =False,\n",
    "        geo=geo_key,\n",
    "        marker = dict(line = dict(color='rgb(227,227,227)',width = 1.5)),\n",
    "        ))\n",
    "    \n",
    "    data.append(dict(\n",
    "        type = 'scattergeo',\n",
    "        showlegend = False,\n",
    "        lon = [-80],\n",
    "        lat = [48],\n",
    "        geo = geo_key,\n",
    "        text = months[i][:-3],\n",
    "        mode = 'text',\n",
    "        ))\n",
    "    layout[geo_key] = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            domain = dict( x = [], y = [] ),\n",
    "            lakecolor = 'rgb(255, 255, 255)')\n",
    "z = 0\n",
    "COLS = 4\n",
    "ROWS = 3\n",
    "for y in reversed(range(ROWS)):\n",
    "    for x in range(COLS):\n",
    "        geo_key = 'geo'+str(z+1) if z != 0 else 'geo'\n",
    "        layout[geo_key]['domain']['x'] = [float(x)/float(COLS), float(x+1)/float(COLS)]\n",
    "        layout[geo_key]['domain']['y'] = [float(y)/float(ROWS), float(y+1)/float(ROWS)]\n",
    "        z=z+1\n",
    "\n",
    "figure = dict(data = data, layout = layout)\n",
    "iplot(figure)\n",
    "\n",
    "########################## NO MORE YEARS ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does population affect air quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "county_pop = pd.read_csv(\"clean_data/county_pop_2010_2017.csv\", encoding='latin-1')\n",
    "county_pop = county_pop.rename(columns = {'April 1, 2010 - Census': '2010 Census',\n",
    "                                          'April 1, 2010 - Estimates Base': 'Estimate Base',\n",
    "                                          'Population Estimate (as of July 1) - 2010': '2010 Estimate',\n",
    "                                          'Population Estimate (as of July 1) - 2011': '2011 Estimate',\n",
    "                                          'Population Estimate (as of July 1) - 2012': '2012 Estimate',\n",
    "                                          'Population Estimate (as of July 1) - 2013': '2013 Estimate',\n",
    "                                          'Population Estimate (as of July 1) - 2014': '2014 Estimate',\n",
    "                                          'Population Estimate (as of July 1) - 2015': '2015 Estimate',\n",
    "                                          'Population Estimate (as of July 1) - 2016': '2016 Estimate',\n",
    "                                          'Population Estimate (as of July 1) - 2017': '2017 Estimate'})\n",
    "county_pop[\"County\"] = county_pop['Geography'].apply(lambda x: x.split(\", \")[0].lower())\n",
    "county_pop[\"County\"] = county_pop[\"County\"].apply(lambda x: x.replace(\" county\", \"\"))\n",
    "county_pop[\"County\"] = county_pop[\"County\"].apply(lambda x: x.replace(\" parish\", \"\"))\n",
    "county_pop[\"State\"] = county_pop['Geography'].apply(lambda x: x.split(\", \")[-1])\n",
    "county_pop = county_pop.replace({\"State\": us_state_abbrevu})\n",
    "county_pop = county_pop.replace({\"State\": state_codes})\n",
    "county_pop = county_pop.rename(columns = {\"State\": \"State Code (FIPS)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "air_quality = pd.read_csv(\"clean_data/county_aqi_1980_2018.csv\")\n",
    "air_quality = air_quality.drop(columns = 'Unnamed: 0')\n",
    "air_quality['County'] = air_quality['County'].apply(lambda x: x.lower())\n",
    "air_quality = air_quality.replace({\"State\": us_state_abbrev})\n",
    "air_quality = air_quality.replace({\"State\": state_codes})\n",
    "air_quality = air_quality.rename(columns = {\"State\": \"State Code (FIPS)\"})\n",
    "\n",
    "fips_17 = pd.read_excel(\"Resources/Yearly_FIPS/all-geocodes-v2017.xlsx\", skiprows = 4)\n",
    "fips_17 = fips_17 [fips_17 ['Area Name (including legal/statistical area description)'].str.contains(\"County|Parish\")]\n",
    "fips_17 = fips_17[[\"State Code (FIPS)\", \"County Code (FIPS)\",'Area Name (including legal/statistical area description)']]\n",
    "fips_17['State Code (FIPS)'] = fips_17['State Code (FIPS)'].apply(lambda x: str(x).zfill(2))\n",
    "fips_17['County Code (FIPS)'] = fips_17['County Code (FIPS)'].apply(lambda x: str(x).zfill(3))\n",
    "fips_17['FIPS'] = fips_17['State Code (FIPS)'] + fips_17['County Code (FIPS)']\n",
    "fips_17 = fips_17.rename(columns = {'Area Name (including legal/statistical area description)' : \"County\"})\n",
    "fips_17[\"County\"] = fips_17['County'].apply(lambda x: x.split(\",\")[0].lower())\n",
    "fips_17[\"County\"] = fips_17[\"County\"].apply(lambda x: x.replace(\" county\", \"\"))\n",
    "fips_17[\"County\"] = fips_17[\"County\"].apply(lambda x: x.replace(\" parish\", \"\"))\n",
    "\n",
    "merged_data = pd.merge(left = fips_17,right = air_quality, how='left', on=['County', 'State Code (FIPS)'])\n",
    "merged_data_nonan = merged_data [np.isfinite(merged_data['Max AQI'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "df2010 = merged_data_nonan.loc[merged_data_nonan['Year'] == 2010]\n",
    "df2010 = pd.merge(left = df2010, right = county_pop, how='left', on=['County', 'State Code (FIPS)'])\n",
    "county_pops2010 = df2010[\"2010 Estimate\"].apply(int)\n",
    "good_days2010 = df2010[\"% Days Good\"].apply(int)\n",
    "unhealthy_days2010 = df2010[\"% Days Unhealthy\"].apply(int)\n",
    "unhealthys_days2010 = df2010[\"% Days Unhealthy for Sensitive Groups\"].apply(int)\n",
    "moderate_days2010 = df2010[\"% Days Moderate\"].apply(int)\n",
    "hazard_days2010 = df2010[\"% Days Hazardous\"].apply(int)\n",
    "max_aqi2010 = df2010[\"Max AQI\"].apply(int)\n",
    "lmax2010 = (max_aqi2010)\n",
    "\n",
    "df2011 = merged_data_nonan.loc[merged_data_nonan['Year'] == 2011]\n",
    "df2011 = pd.merge(left = df2011, right = county_pop, how='left', on=['County', 'State Code (FIPS)'])\n",
    "county_pops2011 = df2011[\"2011 Estimate\"].apply(int)\n",
    "good_days2011 = df2011[\"% Days Good\"].apply(int)\n",
    "unhealthy_days2011 = df2011[\"% Days Unhealthy\"].apply(int)\n",
    "unhealthys_days2011 = df2011[\"% Days Unhealthy for Sensitive Groups\"].apply(int)\n",
    "moderate_days2011 = df2011[\"% Days Moderate\"].apply(int)\n",
    "hazard_days2011 = df2011[\"% Days Hazardous\"].apply(int)\n",
    "max_aqi2011 = df2011[\"Max AQI\"].apply(int)\n",
    "lmax2011 = (max_aqi2011)\n",
    "\n",
    "df2012 = merged_data_nonan.loc[merged_data_nonan['Year'] == 2012]\n",
    "df2012 = pd.merge(left = df2012, right = county_pop, how='left', on=['County', 'State Code (FIPS)'])\n",
    "county_pops2012 = df2012[\"2012 Estimate\"]\n",
    "good_days2012 = df2012[\"% Days Good\"]\n",
    "unhealthy_days2012 = df2012[\"% Days Unhealthy\"].apply(int)\n",
    "unhealthys_days2012 = df2012[\"% Days Unhealthy for Sensitive Groups\"].apply(int)\n",
    "moderate_days2012 = df2012[\"% Days Moderate\"].apply(int)\n",
    "hazard_days2012 = df2012[\"% Days Hazardous\"].apply(int)\n",
    "max_aqi2012 = df2012[\"Max AQI\"].apply(int)\n",
    "lmax2012 = (max_aqi2012)\n",
    "\n",
    "df2013 = merged_data_nonan.loc[merged_data_nonan['Year'] == 2013]\n",
    "df2013 = pd.merge(left = df2013, right = county_pop, how='left', on=['County', 'State Code (FIPS)'])\n",
    "county_pops2013 = df2013[\"2013 Estimate\"].apply(int)\n",
    "good_days2013 = df2013[\"% Days Good\"].apply(int)\n",
    "unhealthy_days2013 = df2013[\"% Days Unhealthy\"].apply(int)\n",
    "unhealthys_days2013 = df2013[\"% Days Unhealthy for Sensitive Groups\"].apply(int)\n",
    "moderate_days2013 = df2013[\"% Days Moderate\"].apply(int)\n",
    "hazard_days2013 = df2013[\"% Days Hazardous\"].apply(int)\n",
    "max_aqi2013 = df2013[\"Max AQI\"].apply(int)\n",
    "lmax2013 = (max_aqi2013)\n",
    "\n",
    "df2014 = merged_data_nonan.loc[merged_data_nonan['Year'] == 2014]\n",
    "df2014 = pd.merge(left = df2014, right = county_pop, how='left', on=['County', 'State Code (FIPS)'])\n",
    "county_pops2014 = df2014[\"2014 Estimate\"].apply(int)\n",
    "good_days2014 = df2014[\"% Days Good\"].apply(int)\n",
    "unhealthy_days2014 = df2014[\"% Days Unhealthy\"].apply(int)\n",
    "unhealthys_days2014 = df2014[\"% Days Unhealthy for Sensitive Groups\"].apply(int)\n",
    "moderate_days2014 = df2014[\"% Days Moderate\"].apply(int)\n",
    "hazard_days2014 = df2014[\"% Days Hazardous\"].apply(int)\n",
    "max_aqi2014 = df2014[\"Max AQI\"].apply(int)\n",
    "lmax2014 = (max_aqi2014)\n",
    "\n",
    "df2015 = merged_data_nonan.loc[merged_data_nonan['Year'] == 2015]\n",
    "df2015 = pd.merge(left = df2015, right = county_pop, how='left', on=['County', 'State Code (FIPS)'])\n",
    "county_pops2015 = df2015[\"2015 Estimate\"].apply(int)\n",
    "good_days2015 = df2015[\"% Days Good\"].apply(int)\n",
    "unhealthy_days2015 = df2015[\"% Days Unhealthy\"].apply(int)\n",
    "unhealthys_days2015 = df2015[\"% Days Unhealthy for Sensitive Groups\"].apply(int)\n",
    "moderate_days2015 = df2015[\"% Days Moderate\"].apply(int)\n",
    "hazard_days2015 = df2015[\"% Days Hazardous\"].apply(int)\n",
    "max_aqi2015 = df2015[\"Max AQI\"].apply(int)\n",
    "lmax2015 = (max_aqi2015)\n",
    "\n",
    "df2016 = merged_data_nonan.loc[merged_data_nonan['Year'] == 2016]\n",
    "df2016 = pd.merge(left = df2016, right = county_pop, how='left', on=['County', 'State Code (FIPS)'])\n",
    "county_pops2016 = df2016[\"2016 Estimate\"].apply(int)\n",
    "good_days2016 = df2016[\"% Days Good\"].apply(int)\n",
    "unhealthy_days2016 = df2016[\"% Days Unhealthy\"].apply(int)\n",
    "unhealthys_days2016 = df2016[\"% Days Unhealthy for Sensitive Groups\"].apply(int)\n",
    "moderate_days2016 = df2016[\"% Days Moderate\"].apply(int)\n",
    "hazard_days2016 = df2016[\"% Days Hazardous\"].apply(int)\n",
    "max_aqi2016 = df2016[\"Max AQI\"].apply(int)\n",
    "lmax2016 = (max_aqi2016)\n",
    "\n",
    "df2017 = merged_data_nonan.loc[merged_data_nonan['Year'] == 2017]\n",
    "df2017 = pd.merge(left = df2017, right = county_pop, how='left', on=['County', 'State Code (FIPS)'])\n",
    "county_pops2017 = df2017[\"2017 Estimate\"].apply(int)\n",
    "good_days2017 = df2017[\"% Days Good\"].apply(int)\n",
    "unhealthy_days2017 = df2017[\"% Days Unhealthy\"].apply(int)\n",
    "unhealthys_days2017 = df2017[\"% Days Unhealthy for Sensitive Groups\"].apply(int)\n",
    "moderate_days2017 = df2017[\"% Days Moderate\"].apply(int)\n",
    "hazard_days2017 = df2017[\"% Days Hazardous\"].apply(int)\n",
    "max_aqi2017 = df2017[\"Max AQI\"].apply(int)\n",
    "lmax2017 = (max_aqi2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "r = []\n",
    "plt.scatter(county_pops2010, \n",
    "            good_days2010, \n",
    "            c=\"red\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2010\")\n",
    "z = np.polyfit(county_pops2010, good_days2010, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2010,p(county_pops2010), color = \"red\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2010, good_days2010)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2011, \n",
    "            good_days2011, \n",
    "            c=\"coral\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2011\")\n",
    "z = np.polyfit(county_pops2011, good_days2011, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2011,p(county_pops2011), color = \"coral\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2011, good_days2011)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2012, \n",
    "            good_days2012,\n",
    "            c=\"orange\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2012\")\n",
    "z = np.polyfit(county_pops2012, good_days2012, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2012,p(county_pops2012), color = \"orange\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2012, good_days2012)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2013, \n",
    "            good_days2013, \n",
    "            c=\"pink\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2013\")\n",
    "z = np.polyfit(county_pops2013, good_days2013, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2013,p(county_pops2013), color = \"pink\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2013, good_days2013)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2014, \n",
    "            good_days2014,\n",
    "            c=\"gold\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2014\")\n",
    "z = np.polyfit(county_pops2014, good_days2014, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2014,p(county_pops2014), color = \"gold\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2014, good_days2014)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2015, \n",
    "            good_days2015,\n",
    "            c=\"yellow\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2015\")\n",
    "z = np.polyfit(county_pops2015, good_days2015, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2015,p(county_pops2015), color = \"yellow\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2015, good_days2015)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2016, \n",
    "            good_days2016, \n",
    "            c=\"lightgreen\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2016\")\n",
    "z = np.polyfit(county_pops2016, good_days2016, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2016,p(county_pops2016), color = \"lightgreen\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2016, good_days2016)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2017, \n",
    "            good_days2017,\n",
    "            c=\"green\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2017\")\n",
    "z = np.polyfit(county_pops2017, good_days2017, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2017,p(county_pops2017), color = \"green\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2017, good_days2017)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.title(\"% Good Air Quality Index (AQI) Days vs. Population\")\n",
    "plt.ylabel(\"% Good Days\")\n",
    "plt.xlabel(\"Population\")\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "lgnd = plt.legend(fontsize=\"small\", mode=\"Expanded\", \n",
    "                  numpoints=1, scatterpoints=1, \n",
    "                  loc=\"upper right\", title=\"Years\", \n",
    "                  labelspacing=0.25)\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "\n",
    "\n",
    "avgr = np.mean(r)\n",
    "print(f\"The mean r^2 value is: {avgr}\")\n",
    "plt.show()\n",
    "# plt.savefig(\"Figures/good_days_percent.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "r = []\n",
    "plt.scatter(county_pops2010, \n",
    "            moderate_days2010, \n",
    "            c=\"red\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2010\")\n",
    "z = np.polyfit(county_pops2010, moderate_days2010, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2010,p(county_pops2010), color = \"red\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2010, moderate_days2010)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2011, \n",
    "            moderate_days2011, \n",
    "            c=\"coral\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2011\")\n",
    "z = np.polyfit(county_pops2011, moderate_days2011, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2011,p(county_pops2011), color = \"coral\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2011, moderate_days2011)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2012, \n",
    "            moderate_days2012,\n",
    "            c=\"orange\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2012\")\n",
    "z = np.polyfit(county_pops2012, moderate_days2012, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2012,p(county_pops2012), color = \"orange\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2012, moderate_days2012)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2013, \n",
    "            moderate_days2013, \n",
    "            c=\"pink\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2013\")\n",
    "z = np.polyfit(county_pops2013, moderate_days2013, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2013,p(county_pops2013), color = \"pink\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2013, moderate_days2013)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2014, \n",
    "            moderate_days2014,\n",
    "            c=\"gold\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2014\")\n",
    "z = np.polyfit(county_pops2014, moderate_days2014, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2014,p(county_pops2014), color = \"gold\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2014, moderate_days2014)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2015, \n",
    "            moderate_days2015,\n",
    "            c=\"yellow\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2015\")\n",
    "z = np.polyfit(county_pops2015, moderate_days2015, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2015,p(county_pops2015), color = \"yellow\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2015, moderate_days2015)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2016, \n",
    "            moderate_days2016, \n",
    "            c=\"lightgreen\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2016\")\n",
    "z = np.polyfit(county_pops2016, moderate_days2016, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2016,p(county_pops2016), color = \"lightgreen\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2016, moderate_days2016)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2017, \n",
    "            moderate_days2017,\n",
    "            c=\"green\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2017\")\n",
    "z = np.polyfit(county_pops2017, moderate_days2017, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2017,p(county_pops2017), color = \"green\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2017, moderate_days2017)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.title(\"% Moderate Air Quality Index (AQI) Days vs. Population\")\n",
    "plt.ylabel(\"% Moderate Days\")\n",
    "plt.xlabel(\"Population\")\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "lgnd = plt.legend(fontsize=\"small\", mode=\"Expanded\", \n",
    "                  numpoints=1, scatterpoints=1, \n",
    "                  loc=\"upper right\", title=\"Years\", \n",
    "                  labelspacing=0.25)\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "\n",
    "\n",
    "avgr = np.mean(r)\n",
    "print(f\"The mean r^2 value is: {avgr}\")\n",
    "plt.show()\n",
    "# plt.savefig(\"Figures/moderate_days_percent.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "r = []\n",
    "plt.scatter(county_pops2010, \n",
    "            unhealthys_days2010, \n",
    "            c=\"red\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2010\")\n",
    "z = np.polyfit(county_pops2010, unhealthys_days2010, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2010,p(county_pops2010), color = \"red\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2010, unhealthys_days2010)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2011, \n",
    "            unhealthys_days2011, \n",
    "            c=\"coral\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2011\")\n",
    "z = np.polyfit(county_pops2011, unhealthys_days2011, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2011,p(county_pops2011), color = \"coral\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2011, unhealthys_days2011)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2012, \n",
    "            unhealthys_days2012,\n",
    "            c=\"orange\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2012\")\n",
    "z = np.polyfit(county_pops2012, unhealthys_days2012, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2012,p(county_pops2012), color = \"orange\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2012, unhealthys_days2012)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2013, \n",
    "            unhealthys_days2013, \n",
    "            c=\"pink\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2013\")\n",
    "z = np.polyfit(county_pops2013, unhealthys_days2013, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2013,p(county_pops2013), color = \"pink\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2013, unhealthys_days2013)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2014, \n",
    "            unhealthys_days2014,\n",
    "            c=\"gold\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2014\")\n",
    "z = np.polyfit(county_pops2014, unhealthys_days2014, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2014,p(county_pops2014), color = \"gold\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2014, unhealthys_days2014)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2015, \n",
    "            unhealthys_days2015,\n",
    "            c=\"yellow\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2015\")\n",
    "z = np.polyfit(county_pops2015, unhealthys_days2015, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2015,p(county_pops2015), color = \"yellow\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2015, unhealthys_days2015)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2016, \n",
    "            unhealthys_days2016, \n",
    "            c=\"lightgreen\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2016\")\n",
    "z = np.polyfit(county_pops2016, unhealthys_days2016, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2016,p(county_pops2016), color = \"lightgreen\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2016, unhealthys_days2016)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2017, \n",
    "            unhealthys_days2017,\n",
    "            c=\"green\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2017\")\n",
    "z = np.polyfit(county_pops2017, unhealthys_days2017, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2017,p(county_pops2017), color = \"green\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2017, unhealthys_days2017)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.title(\"% Unhealthy for Sensitive Groups Air Quality Index (AQI) Days vs. Population\")\n",
    "plt.ylabel(\"% Unhealthy for Sensitive Groups Days\")\n",
    "plt.xlabel(\"Population\")\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "lgnd = plt.legend(fontsize=\"small\", mode=\"Expanded\", \n",
    "                  numpoints=1, scatterpoints=1, \n",
    "                  loc=\"upper right\", title=\"Years\", \n",
    "                  labelspacing=0.25)\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "\n",
    "\n",
    "avgr = np.mean(r)\n",
    "print(f\"The mean r^2 value is: {avgr}\")\n",
    "plt.show()\n",
    "# plt.savefig(\"Figures/unhealthys_days_percent.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "r = []\n",
    "plt.scatter(county_pops2010, \n",
    "            unhealthy_days2010, \n",
    "            c=\"red\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2010\")\n",
    "z = np.polyfit(county_pops2010, unhealthy_days2010, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2010,p(county_pops2010), color = \"red\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2010, unhealthy_days2010)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2011, \n",
    "            unhealthy_days2011, \n",
    "            c=\"coral\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2011\")\n",
    "z = np.polyfit(county_pops2011, unhealthy_days2011, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2011,p(county_pops2011), color = \"coral\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2011, unhealthy_days2011)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2012, \n",
    "            unhealthy_days2012,\n",
    "            c=\"orange\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2012\")\n",
    "z = np.polyfit(county_pops2012, unhealthy_days2012, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2012,p(county_pops2012), color = \"orange\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2012, unhealthy_days2012)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2013, \n",
    "            unhealthy_days2013, \n",
    "            c=\"pink\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2013\")\n",
    "z = np.polyfit(county_pops2013, unhealthy_days2013, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2013,p(county_pops2013), color = \"pink\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2013, unhealthy_days2013)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2014, \n",
    "            unhealthy_days2014,\n",
    "            c=\"gold\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2014\")\n",
    "z = np.polyfit(county_pops2014, unhealthy_days2014, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2014,p(county_pops2014), color = \"gold\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2014, unhealthy_days2014)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2015, \n",
    "            unhealthy_days2015,\n",
    "            c=\"yellow\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2015\")\n",
    "z = np.polyfit(county_pops2015, unhealthy_days2015, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2015,p(county_pops2015), color = \"yellow\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2015, unhealthy_days2015)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2016, \n",
    "            unhealthy_days2016, \n",
    "            c=\"lightgreen\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2016\")\n",
    "z = np.polyfit(county_pops2016, unhealthy_days2016, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2016,p(county_pops2016), color = \"lightgreen\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2016, unhealthy_days2016)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.scatter(county_pops2017, \n",
    "            unhealthy_days2017,\n",
    "            c=\"green\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"2017\")\n",
    "z = np.polyfit(county_pops2017, unhealthy_days2017, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(county_pops2017,p(county_pops2017), color = \"green\", linestyle = \"--\")\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(county_pops2017, unhealthy_days2017)\n",
    "r.append(r_value*r_value)\n",
    "\n",
    "plt.title(\"% Unhealthy Air Quality Index (AQI) Days vs. Population\")\n",
    "plt.ylabel(\"% Unhealthy Days\")\n",
    "plt.xlabel(\"Population\")\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "lgnd = plt.legend(fontsize=\"small\", mode=\"Expanded\", \n",
    "                  numpoints=1, scatterpoints=1, \n",
    "                  loc=\"upper right\", title=\"Years\", \n",
    "                  labelspacing=0.25)\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "\n",
    "\n",
    "avgr = np.mean(r)\n",
    "print(f\"The mean r^2 value is: {avgr}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = make_scatterplot(aqi, group_by=['State'], \n",
    "                 y='% Days AQI Unhealthy-Hazardous', x='Max AQI', linestyle='', return_obj=True)\n",
    "\n",
    "b = make_scatterplot(aqi, group_by=['State'], \n",
    "                 y='% Days AQI Unhealthy-Hazardous', x='Max AQI', linestyle='', return_obj=True)\n",
    "\n",
    "c =make_scatterplot(aqi, group_by=['State'], \n",
    "                 y='% Days AQI Unhealthy-Hazardous', \n",
    "                 x='% Days PM10', linestyle='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in aggregated data\n",
    "df = pd.read_csv('clean_data/DATA_meds.csv', index_col=0)\n",
    "df = df[['State', 'State Abbreviation', 'Year', 'Cancer Sites', 'Count', \n",
    "         'Median % Days AQI Unhealthy-Hazardous', 'Median Max AQI', 'Median 90th Percentile AQI', \n",
    "         'Median % Days CO', 'Median % Days NO2', 'Median % Days SO2',\n",
    "         'Median % Days Ozone', 'Median % Days PM2.5', 'Median % Days PM10']]\n",
    "print(\"Combined data headers:\\n\", df.keys().tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Is there a relationship between exposure to poor air quality and incidences of cancer?\n",
    "- Visualization: scatterplots\n",
    "    - X: % of days measured with AQI above unhealthy\n",
    "    - Y: Cancer count\n",
    "    - Groups:\n",
    "        - State\n",
    "        - Year \n",
    "        - Type of cancer\n",
    "- Analysis: correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by type of cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove summary data from df\n",
    "cancer_type_df = df.loc[df['Cancer Sites'] != 'All Invasive Cancer Sites Combined']\n",
    "print('Total number of different cancer sites in data:', len(cancer_type_df['Cancer Sites'].unique()))\n",
    "\n",
    "# Find most prevalent cancers overall\n",
    "top_cancers = cancer_type_df.groupby('Cancer Sites')[['Count']].sum().sort_values('Count', ascending=False)[:10].reset_index()\n",
    "top_cancers = top_cancers['Cancer Sites'].tolist()\n",
    "print('Top 10 most prevalent cancer sites:', ', '.join(top_cancers))\n",
    "\n",
    "# Create df for scatterplot which contains only the most common cancers\n",
    "top_cancer_type_df = cancer_type_df.loc[cancer_type_df['Cancer Sites'].isin(top_cancers)]\n",
    "top_cancer_type_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_scatterplot(top_cancer_type_df, group_by=['Cancer Sites'], \n",
    "                 x='Median % Days AQI Unhealthy-Hazardous', y='Count', \n",
    "                 xlabel='Median % Days AQI Unhealthy-Hazardous', ylabel='Count of Cancer Incidences Per Year',\n",
    "                 main_title='Cancer Type vs % of Days with Unhealthy to Hazardous AQI Exposure', \n",
    "                 legend_title='Top 10 Most Prevalent Cancers')\n",
    "\n",
    "make_scatterplot(top_cancer_type_df, group_by=['State'], \n",
    "                 x='Median % Days PM2.5', y='Count', \n",
    "                 ylabel='Count of Cancer Incidences Per Year',\n",
    "                 main_title='Cancer Type vs % of Days with Unhealthy to Hazardous AQI Exposure', \n",
    "                 legend_title='Top 10 Most Prevalent Cancers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['Cancer Sites', 'State', 'Year'])['Count','Median % Days AQI Unhealthy-Hazardous'].median().head()\n",
    "#.reset_index()\n",
    "# groups = df.groupby(['Cancer Sites'])['Count','Median % Days AQI Unhealthy-Hazardous']\n",
    "\n",
    "# df.groupby(['Cancer Sites', 'State', 'Year'])['Count','Median % Days AQI Unhealthy-Hazardous'].median()#.reset_index()\n",
    "\n",
    "# df.groupby(['Cancer Sites', 'Year', 'State'])[['Count']].mean().head()\n",
    "df.groupby(['Cancer Sites','Median % Days AQI Unhealthy-Hazardous'])[['Count']].mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_scatterplot(df, group_by=['Year'], \n",
    "                 x='Median Max AQI',\n",
    "                 y='Count', ylabel='Count of Cancer Incidences',\n",
    "                 main_title='Cancer Type vs % of Days with Unhealthy to Hazardous AQI Exposure', \n",
    "                 legend_title='Years')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['Year'], x='% Days CO', y='% Days AQI Unhealthy-Hazardous', linestyle='')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['State'], x='% Days CO', y='% Days AQI Unhealthy-Hazardous', linestyle='')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['Year'], x='% Days NO2', y='% Days AQI Unhealthy-Hazardous', linestyle='')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['State'], x='% Days NO2', y='% Days AQI Unhealthy-Hazardous', linestyle='')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['Year'], x='% Days SO2', y='% Days AQI Unhealthy-Hazardous', linestyle='')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['Year'], x='% Days SO2', y='% Days AQI Unhealthy-Hazardous', linestyle='')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['State'], x='% Days SO2', y='% Days AQI Unhealthy-Hazardous', linestyle='')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['Year'], x='% Days Ozone', y='% Days AQI Unhealthy-Hazardous', linestyle='')\n",
    "\n",
    "make_scatterplot(aqi, group_by=['State'], x='% Days Ozone', y='% Days AQI Unhealthy-Hazardous', linestyle='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the population by county chloropleth:\n",
    "# generate_county_choropleth(county_pop, values='2017 Estimate', fips='FIPS', title='Population by County 2017',data='population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the AQI by county chloropleth:\n",
    "# generate_county_choropleth(county_aqi_median, fips='FIPS',\n",
    "#                            values='Median AQI', title='Median AQI',\n",
    "#                            data='aqi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Does your probability of developing a certain type of cancer change depending on your geographic location in the US?\n",
    "------------\n",
    "- Data: State_cancer_1998_2014.csv \n",
    "\n",
    "- Data Analysis: Chi square (discrete categorical variables)\n",
    "    - Incidences of each type of cancer & Location (state/county/cbsa) \n",
    "        - Null hypothesis: type of cancer unrelated to geographic location / probability of developing a certain type of cancer unrelated to geo location  can be done for each year separately to see how this changes\n",
    "    - AQI category (# days of each?) & Location (state/county/cbsa)\n",
    "        - Null hypothesis: proportions of [aqi category] days the same for each geographic location (homogeneity test)\n",
    "\n",
    "- Visualization: choropleth showing most prevalent type of cancer in each [state/county/cbsa] for each year (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancertypes = cancer.loc[cancer['Cancer Sites'] != 'All Invasive Cancer Sites Combined'].reset_index()\n",
    "chi_df = {}\n",
    "for name, group in cancertypes.groupby(['Year', 'State Abbreviation', 'Cancer Sites']):\n",
    "#     print(name)\n",
    "    yr, state, cancer_type = name\n",
    "    if str(yr) not in chi_df.keys():\n",
    "        chi_df[''.format(yr)] = [{state:[cancer_type, group.Count]}]\n",
    "    else:\n",
    "        chi_df[''.format(yr)].append({state:[cancer_type, group.Count]})\n",
    "#     print(group.Count)\n",
    "print(chi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_cancer = pd.read_csv('clean_data/state_cancer_1998_2014.csv', index_col=0)\n",
    "# state_cancer.head()\n",
    "state_cancer_type = state_cancer.loc[state_cancer['Cancer Sites'] != 'All Invasive Cancer Sites Combined']\n",
    "# state_cancer_type = state_cancer_type.groupby(['State Abbreviation', 'Year', 'Cancer Sites'])[['Count']].max().reset_index()\n",
    "# state_cancer_type = state_cancer_type.groupby(['State Abbreviation', 'Year', 'Cancer Sites'])[['Count']].max().sort_values(['Year','Count'], ascending=False)#.groupby('State')\n",
    "\n",
    "# Get rid of summary data\n",
    "state_cancer_type = state_cancer.loc[state_cancer['Cancer Sites'] != 'All Invasive Cancer Sites Combined']\n",
    "\n",
    "# Group by state, year, and cancer type\n",
    "state_cancer_type = state_cancer_type.groupby(['State Abbreviation', 'Year', 'Cancer Sites'])[['Count']].sum().reset_index()\n",
    "\n",
    "# All ranked by descending count\n",
    "state_cancer_type = state_cancer_type.sort_values('Count', ascending=False).reset_index()\n",
    "\n",
    "state_cancer_type = state_cancer_type.groupby(['State Abbreviation', 'Year', ])[['Cancer Sites','Count']].max().reset_index()\n",
    "\n",
    "# state_cancer_type\n",
    "\n",
    "state_cancer_type.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: How well can you predict [cancer instances/risk] from AQI and year?\n",
    "--------\n",
    "- Data Analysis: Linear Regression\n",
    "    - Response variable: cancer (rate?)\n",
    "    - Explanatory variables: AQI, state, county, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('figure', titlesize=18)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('axes', titlesize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_types = df.loc[df['Cancer Sites'] != 'All Invasive Cancer Sites Combined'].reset_index()\n",
    "\n",
    "# Rename columns\n",
    "newcols = {'State':'state', 'State Abbreviation':'state_abbrev', 'Year':'year', \n",
    "           'Median Max AQI':'aqi_max', 'Median 90th Percentile AQI':'aqi_90th',\n",
    "           'Median % Days AQI Unhealthy-Hazardous':'aqi_pcnt_days_unhealthy', \n",
    "           'Median % Days CO':'pcnt_days_co', 'Median % Days NO2':'pcnt_days_no2',\n",
    "           'Median % Days SO2':'pcnt_days_so2', 'Median % Days Ozone':'pcnt_days_ozone', \n",
    "           'Median % Days PM2.5':'pcnt_days_pm2pt5', 'Median % Days PM10':'pcnt_days_pm10',\n",
    "           'Cancer Sites':'cancer_type', 'Count':'cancer_counts'}\n",
    "cancer_types.rename(columns = newcols, inplace = True)\n",
    "\n",
    "cancer_types = cancer_types[['state', 'state_abbrev', 'year', 'cancer_type',\n",
    "       'cancer_counts', 'aqi_pcnt_days_unhealthy', 'aqi_max', 'aqi_90th',\n",
    "       'pcnt_days_co', 'pcnt_days_no2', 'pcnt_days_so2', 'pcnt_days_ozone',\n",
    "       'pcnt_days_pm2pt5', 'pcnt_days_pm10']]\n",
    "cancer_types.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitted linear regression model\n",
    "variables = ['state', 'year', 'cancer_type',\n",
    "       'aqi_pcnt_days_unhealthy', 'aqi_max', 'aqi_90th', 'pcnt_days_co',\n",
    "       'pcnt_days_no2', 'pcnt_days_so2', 'pcnt_days_ozone', 'pcnt_days_pm2pt5',\n",
    "       'pcnt_days_pm10']\n",
    "model_f = 'cancer_counts ~ {}'.format(' + '.join(variables))\n",
    "\n",
    "model = smf.ols(formula=model_f, data=cancer_types)\n",
    "model_fit = model.fit()\n",
    "# print(model_fit)\n",
    "# model_fit.conf_int()\n",
    "# model_fit.summary()\n",
    "model_fit.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations for plots\n",
    "\n",
    "# fitted values\n",
    "model_fitted_y = model_fit.fittedvalues\n",
    "\n",
    "# model residuals\n",
    "model_residuals = model_fit.resid\n",
    "\n",
    "# normalized residuals\n",
    "model_norm_residuals = model_fit.get_influence().resid_studentized_internal\n",
    "\n",
    "# absolute squared normalized residuals\n",
    "model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
    "\n",
    "# absolute residuals\n",
    "model_abs_resid = np.abs(model_residuals)\n",
    "\n",
    "# leverage, from statsmodels internals\n",
    "model_leverage = model_fit.get_influence().hat_matrix_diag\n",
    "\n",
    "# cook's distance, from statsmodels internals\n",
    "model_cooks = model_fit.get_influence().cooks_distance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "plot_lm_1 = plt.figure(1)\n",
    "plot_lm_1.set_figheight(8)\n",
    "plot_lm_1.set_figwidth(12)\n",
    "\n",
    "plot_lm_1.axes[0] = sns.residplot(model_fitted_y, 'cancer_counts', data=cancer_types, \n",
    "                          lowess=True, \n",
    "                          scatter_kws={'alpha': 0.5}, \n",
    "                          line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
    "plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_1.axes[0].set_ylabel('Residuals')\n",
    "\n",
    "# annotations\n",
    "abs_resid = model_abs_resid.sort_values(ascending=False)\n",
    "abs_resid_top_3 = abs_resid[:3]\n",
    "\n",
    "for i in abs_resid_top_3.index:\n",
    "    plot_lm_1.axes[0].annotate(i, \n",
    "                               xy=(model_fitted_y[i], \n",
    "                                   model_residuals[i]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot - shows how well the distribution of residuals fit the normal distribution\n",
    "\n",
    "QQ = ProbPlot(model_norm_residuals)\n",
    "plot_lm_2 = QQ.qqplot(line='45', alpha=0.5, color='#4C72B0', lw=1)\n",
    "\n",
    "plot_lm_2.set_figheight(8)\n",
    "plot_lm_2.set_figwidth(12)\n",
    "\n",
    "plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
    "plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
    "plot_lm_2.axes[0].set_ylabel('Standardized Residuals');\n",
    "\n",
    "# annotations\n",
    "abs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)\n",
    "abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "\n",
    "for r, i in enumerate(abs_norm_resid_top_3):\n",
    "    plot_lm_2.axes[0].annotate(i, \n",
    "                               xy=(np.flip(QQ.theoretical_quantiles, 0)[r],\n",
    "                                   model_norm_residuals[i]));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale-location plot - residual plot showing spread to asses heteroscedasticity\n",
    "plot_lm_3 = plt.figure(3)\n",
    "plot_lm_3.set_figheight(8)\n",
    "plot_lm_3.set_figwidth(12)\n",
    "\n",
    "plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5)\n",
    "sns.regplot(model_fitted_y, model_norm_residuals_abs_sqrt, \n",
    "            scatter=False, \n",
    "            ci=False, \n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_3.axes[0].set_title('Scale-Location')\n",
    "plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$');\n",
    "\n",
    "# annotations\n",
    "abs_sq_norm_resid = np.flip(np.argsort(model_norm_residuals_abs_sqrt), 0)\n",
    "abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
    "\n",
    "for i in abs_norm_resid_top_3:\n",
    "    plot_lm_3.axes[0].annotate(i, \n",
    "                               xy=(model_fitted_y[i], \n",
    "                                   model_norm_residuals_abs_sqrt[i]));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage plot - shows if any outliers have influence over the regression fit\n",
    "#               - anything outside Cook's Disktance lines may have influencial effect on model fit\n",
    "\n",
    "plot_lm_4 = plt.figure(4)\n",
    "plot_lm_4.set_figheight(8)\n",
    "plot_lm_4.set_figwidth(12)\n",
    "\n",
    "plt.scatter(model_leverage, model_norm_residuals, alpha=0.5)\n",
    "sns.regplot(model_leverage, model_norm_residuals, \n",
    "            scatter=False, \n",
    "            ci=False, \n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "plot_lm_4.axes[0].set_xlim(0, 0.20)\n",
    "plot_lm_4.axes[0].set_ylim(-3, 5)\n",
    "plot_lm_4.axes[0].set_title('Residuals vs Leverage')\n",
    "plot_lm_4.axes[0].set_xlabel('Leverage')\n",
    "plot_lm_4.axes[0].set_ylabel('Standardized Residuals')\n",
    "\n",
    "# annotations\n",
    "leverage_top_3 = np.flip(np.argsort(model_cooks), 0)[:3]\n",
    "\n",
    "for i in leverage_top_3:\n",
    "    plot_lm_4.axes[0].annotate(i, \n",
    "                               xy=(model_leverage[i], \n",
    "                                   model_norm_residuals[i]))\n",
    "    \n",
    "# cook's distance contours\n",
    "def graph(formula, x_range, label=None):\n",
    "    x = x_range\n",
    "    y = formula(x)\n",
    "    plt.plot(x, y, label=label, lw=1, ls='--', color='red')\n",
    "\n",
    "p = len(model_fit.params) # number of model parameters\n",
    "\n",
    "graph(lambda x: np.sqrt((0.5 * p * (1 - x)) / x), \n",
    "      np.linspace(0.001, 0.200, 50), \n",
    "      'Cook\\'s distance') # 0.5 line\n",
    "graph(lambda x: np.sqrt((1 * p * (1 - x)) / x), \n",
    "      np.linspace(0.001, 0.200, 50)) # 1 line\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
